{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"idkROM Documentation","text":"<p>Welcome to the idkROM project documentation. This project is designed for loading, preprocessing, and modeling data using various machine learning techniques. Below you will find an overview of the project\u2019s structure, its components, and how to use it.</p>"},{"location":"#project-overview","title":"Project Overview","text":"<p>idkROM is a machine learning framework that allows users to load data from different sources, preprocess it, and apply various models such as neural networks, Gaussian processes, and radial basis functions. The framework is designed to be flexible and user-friendly, making it suitable for both beginners and experienced practitioners in the field of machine learning.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with idkROM, you need to have Python installed on your machine. You can then clone the repository and install the required dependencies. </p>"},{"location":"#installation","title":"Installation","text":"<ol> <li>Clone the repository:    <pre><code>git clone &lt;repository-url&gt;\n</code></pre></li> <li>Navigate to the project directory:    <pre><code>cd idkROM\n</code></pre></li> <li>Install the required packages:    <pre><code>pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"#usage","title":"Usage","text":"<p>To run the application, use the following command: <pre><code>python main.py &lt;ruta_csv&gt; &lt;tipo_datos: raw/processed&gt; &lt;modelo: neural_network/gaussian_process/rbf&gt;\n</code></pre></p> <p>Replace <code>&lt;ruta_csv&gt;</code> with the path to your CSV file, <code>&lt;tipo_datos&gt;</code> with either <code>raw</code> or <code>processed</code>, and <code>&lt;modelo&gt;</code> with the desired model type.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>Classes: Detailed documentation of the classes used in the project.</li> <li>Functions: Comprehensive descriptions of the functions available in the project.</li> <li>Descriptions: General information about the project, its purpose, and usage guidelines.</li> </ul> <p>For more detailed information, please refer to the respective sections in the documentation.</p>"},{"location":"classes/","title":"Classes Documentation","text":""},{"location":"classes/#dataloader","title":"DataLoader","text":"<p>The <code>DataLoader</code> class is responsible for loading data from various sources, including raw and preprocessed data.</p>"},{"location":"classes/#methods","title":"Methods","text":"<ul> <li><code>load_data(file_path: str, data_source: str) -&gt; DataFrame</code></li> <li>Loads data from the specified file path and data source (raw or processed).</li> </ul>"},{"location":"classes/#pre","title":"Pre","text":"<p>The <code>Pre</code> class handles data preprocessing tasks, including splitting datasets and normalizing inputs and outputs.</p>"},{"location":"classes/#methods_1","title":"Methods","text":"<ul> <li><code>split_dataset(df: DataFrame, last_input_var: int) -&gt; Tuple[DataFrame, DataFrame, DataFrame, DataFrame, DataFrame, DataFrame]</code></li> <li> <p>Splits the dataset into training, validation, and test sets based on the last input variable index.</p> </li> <li> <p><code>preprocessing(X_train: DataFrame, y_train: DataFrame, X_val: DataFrame, y_val: DataFrame, X_test: DataFrame, y_test: DataFrame, scaler_type: str) -&gt; Tuple[DataFrame, DataFrame, DataFrame, DataFrame, DataFrame, DataFrame]</code></p> </li> <li>Normalizes the input and output datasets using the specified scaler type (e.g., \u2018minmax\u2019).</li> </ul>"},{"location":"classes/#neuralnetworkrom","title":"NeuralNetworkROM","text":"<p>The <code>NeuralNetworkROM</code> class implements a neural network model for regression or classification tasks.</p>"},{"location":"classes/#methods_2","title":"Methods","text":"<ul> <li><code>train(X_train: DataFrame, y_train: DataFrame, X_val: DataFrame, y_val: DataFrame) -&gt; None</code></li> <li> <p>Trains the neural network model using the training data and validates it with the validation data.</p> </li> <li> <p><code>predict(X_test: DataFrame) -&gt; DataFrame</code></p> </li> <li> <p>Makes predictions on the test dataset.</p> </li> <li> <p><code>evaluate(X_test: DataFrame, y_test: DataFrame, y_pred: DataFrame, output_scaler: Any) -&gt; None</code></p> </li> <li>Evaluates the model\u2019s performance using the test dataset and predictions.</li> </ul>"},{"location":"classes/#gaussianprocessrom","title":"GaussianProcessROM","text":"<p>The <code>GaussianProcessROM</code> class implements a Gaussian process model for regression tasks.</p>"},{"location":"classes/#methods_3","title":"Methods","text":"<ul> <li><code>train(X_train: DataFrame, y_train: DataFrame, X_val: DataFrame, y_val: DataFrame) -&gt; None</code></li> <li> <p>Trains the Gaussian process model using the training data and validates it with the validation data.</p> </li> <li> <p><code>predict(X_test: DataFrame) -&gt; DataFrame</code></p> </li> <li> <p>Makes predictions on the test dataset.</p> </li> <li> <p><code>evaluate(X_test: DataFrame, y_test: DataFrame, y_pred: DataFrame, output_scaler: Any) -&gt; None</code></p> </li> <li>Evaluates the model\u2019s performance using the test dataset and predictions.</li> </ul>"},{"location":"classes/#rbfrom","title":"RBFROM","text":"<p>The <code>RBFROM</code> class implements a radial basis function model for regression tasks.</p>"},{"location":"classes/#methods_4","title":"Methods","text":"<ul> <li><code>train(X_train: DataFrame, y_train: DataFrame, X_val: DataFrame, y_val: DataFrame) -&gt; None</code></li> <li> <p>Trains the radial basis function model using the training data and validates it with the validation data.</p> </li> <li> <p><code>predict(X_test: DataFrame) -&gt; DataFrame</code></p> </li> <li> <p>Makes predictions on the test dataset.</p> </li> <li> <p><code>evaluate(X_test: DataFrame, y_test: DataFrame, y_pred: DataFrame, output_scaler: Any) -&gt; None</code></p> </li> <li>Evaluates the model\u2019s performance using the test dataset and predictions.</li> </ul>"},{"location":"descriptions/","title":"Project Description","text":"<p>The idkROM project is a machine learning application designed to facilitate the modeling and prediction of data using various algorithms. It provides a user-friendly interface and supports multiple data sources, allowing users to load, preprocess, and analyze data efficiently.</p>"},{"location":"descriptions/#purpose","title":"Purpose","text":"<p>The primary purpose of this project is to implement different machine learning models, including neural networks, Gaussian processes, and radial basis function models. The application aims to provide users with tools to train these models, evaluate their performance, and make predictions based on input data.</p>"},{"location":"descriptions/#features","title":"Features","text":"<ul> <li>Data Loading: The application can load raw and preprocessed data from various sources, making it flexible for different use cases.</li> <li>Data Preprocessing: It includes functionality for splitting datasets and normalizing inputs and outputs to ensure optimal model performance.</li> <li>Model Training: Users can train different types of models, including neural networks, Gaussian processes, and radial basis functions, with the ability to search for the best hyperparameters.</li> <li>Evaluation and Prediction: The application provides methods for evaluating model performance and making predictions on test datasets.</li> </ul>"},{"location":"descriptions/#usage","title":"Usage","text":"<p>To use the idkROM application, follow these steps:</p> <ol> <li>Install Dependencies: Ensure that all required libraries and dependencies are installed.</li> <li>Prepare Data: Have your data ready in CSV format, either raw or preprocessed.</li> <li>Run the Application: Execute the main script with the appropriate command-line arguments to load data, preprocess it, and train the desired model.</li> </ol> <p>Example command: <pre><code>python main.py &lt;ruta_csv&gt; &lt;tipo_datos: raw/processed&gt; &lt;modelo: neural_network/gaussian_process/rbf&gt;\n</code></pre></p> <ol> <li>View Results: After training, the application will output evaluation metrics and predictions based on the test dataset.</li> </ol> <p>This project serves as a comprehensive tool for users interested in applying machine learning techniques to their data analysis tasks.</p>"},{"location":"functions/","title":"Functions Documentation","text":""},{"location":"functions/#dataloader-class","title":"DataLoader Class","text":""},{"location":"functions/#methods","title":"Methods","text":""},{"location":"functions/#load_datafile_path-str-data_source-str-pddataframe","title":"<code>load_data(file_path: str, data_source: str) -&gt; pd.DataFrame</code>","text":"<p>Loads data from the specified file path and data source (either raw or processed).</p> <ul> <li>Parameters:</li> <li><code>file_path</code>: The path to the data file.</li> <li><code>data_source</code>: The type of data to load (\u2018raw\u2019 or \u2018processed\u2019).</li> <li>Returns: A pandas DataFrame containing the loaded data.</li> </ul>"},{"location":"functions/#pre-class","title":"Pre Class","text":""},{"location":"functions/#methods_1","title":"Methods","text":""},{"location":"functions/#split_datasetdf-pddataframe-last_input_var-int-tuplenpndarray-npndarray-npndarray-npndarray-npndarray-npndarray","title":"<code>split_dataset(df: pd.DataFrame, last_input_var: int) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]</code>","text":"<p>Splits the DataFrame into training, validation, and test sets.</p> <ul> <li>Parameters:</li> <li><code>df</code>: The DataFrame containing the data.</li> <li><code>last_input_var</code>: The index of the last input variable.</li> <li>Returns: A tuple containing the training inputs, training outputs, validation inputs, validation outputs, test inputs, and test outputs.</li> </ul>"},{"location":"functions/#preprocessingx_train-npndarray-y_train-npndarray-x_val-npndarray-y_val-npndarray-x_test-npndarray-y_test-npndarray-scaler_type-str-tuplenpndarray-npndarray-npndarray-npndarray-npndarray-npndarray","title":"<code>preprocessing(X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray, X_test: np.ndarray, y_test: np.ndarray, scaler_type: str) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]</code>","text":"<p>Normalizes the input and output data using the specified scaler type.</p> <ul> <li>Parameters:</li> <li><code>X_train</code>: Training input data.</li> <li><code>y_train</code>: Training output data.</li> <li><code>X_val</code>: Validation input data.</li> <li><code>y_val</code>: Validation output data.</li> <li><code>X_test</code>: Test input data.</li> <li><code>y_test</code>: Test output data.</li> <li><code>scaler_type</code>: The type of scaler to use (\u2018minmax\u2019 or others).</li> <li>Returns: A tuple containing the normalized training inputs, training outputs, validation inputs, validation outputs, test inputs, and test outputs.</li> </ul>"},{"location":"functions/#search_best_hyperparameters-function","title":"search_best_hyperparameters Function","text":""},{"location":"functions/#search_best_hyperparametersmodel_name-str-x_train-npndarray-y_train-npndarray-search_type-str-n_iter-int-dictstr-any","title":"<code>search_best_hyperparameters(model_name: str, X_train: np.ndarray, y_train: np.ndarray, search_type: str, n_iter: int) -&gt; Dict[str, Any]</code>","text":"<p>Searches for the best hyperparameters for the specified model using the given search type.</p> <ul> <li>Parameters:</li> <li><code>model_name</code>: The name of the model (\u2018neural_network\u2019, \u2018gaussian_process\u2019, or \u2018rbf\u2019).</li> <li><code>X_train</code>: Training input data.</li> <li><code>y_train</code>: Training output data.</li> <li><code>search_type</code>: The type of search to perform (\u2018random\u2019 or others).</li> <li><code>n_iter</code>: The number of iterations for the search.</li> <li>Returns: A dictionary containing the best hyperparameters found during the search.</li> </ul>"}]}